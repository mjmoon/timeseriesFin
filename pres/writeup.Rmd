---
title: "Predicting MLB game winners using the Kalman filter"
author: "Michael Moon and Aaron Situ"
date: "August 9, 2016"
output: html_document
---

### Data ###
#### Parsing retrosheet ####
The data used for the study was retrieved using the package `retrosheet`. The package retrieves and parses MLB data from <http://www.retrosheet.org/>. The type of data that can be retrieved include play-by-play data, game logs, and schedules from as far back as 1871. 

For the study, game logs for all regular season games from 2011 to 2015 seasons were downloaded. The following variables were included with the retrieved data.

+ **Date**: Game date
+ **HmTm**: Home team code
+ **VisTm**: Visiting team code
+ **HmLine**: Home team's final line score
+ **VisLine**: Visiting team's final line score
+ **DblHdr**: Doubleheader indicator (*0*: Not a doubleheader; *1*: 1st game of a doubleheader; *2*: 2nd game of a doubleheader)

Below is the code used to retrieve and parse the score differentials. Each game was separated into two lines for each of the home and away team with an indicator variable.

+ **HmVis**: *+1*: Home team; *-1*: Visiting team

```{r offwarn, include = FALSE}
options(warn = -1, eval = FALSE)
```

```{r getdata, message = FALSE}
library(retrosheet)
yrs <- c(2011:2015)
teamIds <- unique(c(sapply(yrs, getTeamIDs)))
teamIds <- teamIds[teamIds != "FLO"] # Florida Marlins changed to Miami Marlins

# Variables: Teams, Line scores, Date; DblHdr; 
fields <- c("HmTm", "VisTm", "HmLine", "VisLine", "Date", "DblHdr")
dataGame <- lapply(yrs, function(x) getPartialGamelog(x, fields)) 
dataGame <- lapply(dataGame, as.data.frame)

parseSeason <- function(season){
  season$GID <- paste(paste(season$Date, season$HmTm, sep = "-"), season$DblHdr, sep = "")
  season$Tind <- as.numeric(factor(season$Date))
  season$Date <- as.Date(season$Date, "%Y%m%d")
  season$DblHdr <- as.factor(season$DblHdr)
  # Florida Marlins changed to Miami Marlins
  season$VisTm[season$VisTm == "FLO"] <- "MIA"
  season$VisTm <- factor(season$VisTm, teamIds)
  season$HmTm[season$HmTm == "FLO"] <- "MIA"
  season$HmTm <- factor(season$HmTm, teamIds)
  season$Host <- season$HmTm
  season$ScoreDiffHm <- 
    sapply(strsplit(season$HmLine, ""), 
           function(x) sum(as.numeric(x), na.rm = TRUE)) -
    sapply(strsplit(season$VisLine, ""), 
           function(x) sum(as.numeric(x), na.rm = TRUE))
  tmpVis <- subset(season, select = c("GID", "Tind", "Date", "DblHdr", "VisTm", 
                                      "Host", "ScoreDiffHm"))
  names(tmpVis) <- c("GID", "Tind", "Date", "DblHdr", "Team", 
                     "Host", "ScoreDiff")
  tmpVis$ScoreDiff <- -tmpVis$ScoreDiff
  tmpVis$HmVis <- -1
  
  
  tmpHm <- subset(season, select = c("GID", "Tind", "Date", "DblHdr", "HmTm", 
                                      "Host", "ScoreDiffHm"))
  names(tmpHm) <- c("GID", "Tind", "Date", "DblHdr", "Team", 
                     "Host", "ScoreDiff")
  tmpHm$HmVis <- 1
  
  
  tmp <- rbind(tmpVis, tmpHm)
  return(tmp[order(tmp$Date, tmp$Host), ])
}

dataSeasons <- lapply(dataGame, parseSeason)
names(dataSeasons) <- c( "S2011", "S2012", "S2013", "S2014", "S2015")
```

There were total `r sum(sapply(dataGame, nrow))`games. There Below is a sample of the data after parsing. 

```{r}
head(dataSeasons$S2011, 10)
```

#### Parsing schedules ####
The following code was used to create the schedule matrices. $$C_t$$

```{r createC}
library(plyr)
library(reshape2)
parseMatches <- function(season){
  tmp <- ddply(season, c("Date", "Tind"), 
               function(x) dcast(x, GID ~ Team, sum, value.var = "HmVis"))
  tmp[is.na(tmp)] <- 0
  tmp <- tmp[c("Date", "Tind", teamIds)] # match the column order
  return(tmp)
}

matchSeasons <- lapply(dataSeasons, parseMatches)
names(matchSeasons) <- c("S2011", "S2012", "S2013", "S2014", "S2015")
```

Below is a sample of the schedule data after parsing. 

```{r}
head(matchSeasons$S2011, 10)
```

#### Parsing score differentials ####
The following code was used to create the score differential vectors. $$y_t$$

```{r createY}
scoreSeasons <- lapply(dataSeasons, function(x) subset(x, HmVis == 1, 
                  select = c("Date", "Tind", "ScoreDiff")))
names(scoreSeasons) <- c("S2011", "S2012", "S2013", "S2014", "S2015")
```

Below is a sample of the score differential data after parsing.

```{r}
head(scoreSeasons$S2011)
```

#### Parsing covariates ####
The following code was used to create the covariate matrices including an intercept term. $$D_t$$

```{r createD}
parseCovs <- function(season){
  tmp <- subset(season, HmVis == 1, select = c("Date", "Tind", "DblHdr", "Host"))
  row.names(tmp) <- NULL
  tmp <- cbind(tmp[,c(1,2)], model.matrix(~tmp$DblHdr + tmp$Host))
  return(tmp)
}
covSeasons <- lapply(dataSeasons, parseCovs)
names(covSeasons) <- c("S2011", "S2012", "S2013", "S2014", "S2015")
```

Below is a sample of the covariate matrices after parsing.

```{r}
head(covSeasons$S2011)[,1:8]
```
```

#### Accessing data ####
To retrieve the matrices and vectors for each day `t`, the following `get` functions were created.

```{r getFunctions}
### get data for day t ###
getByTind <- function(x, tind){
  return(x[x$Tind == tind, -c(1,2), drop = F])
}
### get the schedule matrix for day t ###
getC <- function(t, seasoni){
  return(as.matrix(getByTind(matchSeasons[[seasoni]], t)))
}
### get the score differential vector for day t ###
getY <- function(t, seasoni){
  return(as.matrix(getByTind(scoreSeasons[[seasoni]], t)))
}
### get the covariate matrix for day t ###
#### level = 2: intercept; doubleheader; hosting team
#### level = 1: intercept; doubleheader
#### level = 0: intercept only
getD <- function(t, seasoni, level = 2){
  D <- as.matrix(getByTind(covSeasons[[seasoni]], t))
  if(level < 2)
    if(level > 0) D <- D[ , c(1:3)]
    else D <- D[ , 1]
  return(D)
}
```

For the Kalman filter functions used, the number of rows must match for different $t$'s. The following function was created to ensure all matrices and vectors had `r gamedays <- sapply(scoreSeasons, function(x) unique(x$Tind)); max(sapply(c(1:5), function(x) max(sapply(gamedays[[x]], function(y) length(getY(y, x))))))` - the maximum number of a game on a day - rows.

```{r get18Functions}
getC18 <- function(t, seasoni){
  c <- getC(t, seasoni)
  return(rbind(c, matrix(0, nrow = 18 - nrow(c), ncol = ncol(c))))
}

getD18 <- function(t, seasoni, level = 2){
  d <- getD(t, seasoni, level = level)
  if(level == 0)
    return(c(d, rep(0, 18 - length(d))))
  return(rbind(d, matrix(0, nrow = 18 - nrow(d), ncol = ncol(d))))
}

getY18 <- function(t, seasoni){
  y <- getY(t, seasoni)
  return(c(y, rep(0, 18 - length(y))))
}
```

### Analysis ###
#### Estimating parameters ####
The following parameters were estimated prior to the Kalman filter algorithm. The first 20 games of each season were used to estimate the parameters and only the remaining matches were used in the Kalman filter.

**System variances**

$$\sigma_0^2, \sigma_v^2, \sigma_w^2 \in \mathbb{R}$$

**Covariate coefficients**

$$u = \{ u_1, \dots , u_{32} \} \in \mathbb{R}^{32}$$

The coefficients include the intercept, $u_1$, coefficients for doubleheader dummy variables, $\{u_2, u_3, u_4\}$, and coefficients for hosting team dummy variables, $\{u_5, \dots , u_{32}\}$.

For the fist intercept-only model, we estimated the paramters by maximizing the log-likelihood function given below. The likelihood function can be derived from the conditional distribution of  $y_t$. 

**Conditional distribution**
$$y_t|\mathcal{Y}_{t-1}\sim N(\hat{y}_t, \hat{O}_t) \\ \text{   where }\mathcal{Y}_t:=(y'_1,\dots,y'_t); \hat{y}_t=C_{t}\hat{x}_{t|t-1}+D_{t}u; \hat{O}_t=C_{t}\hat{\Sigma}_{t|t-1}C'_{t+1}+N_{t}$$
**Density**
$$f_{y_t|\mathcal{Y}_{t-1}}(y_t|\mathcal{Y}_{t-1}) \propto |\hat{O}_t|^{-1/2}  \text{exp}\left(-\frac{1}{2}(y_t-\hat{y}_t)'\hat{O}_t^{-1}(y_t-\hat{y}_t)\right)$$
**Log-likelihood**
$$\mathscr{l}(\sigma_0^2, \sigma_v^2, \sigma_w^2, u_1; \mathcal{Y}_T)=\sum_{t=1}^{\mathcal{Y}} \text{log }f_{y_t|\mathcal{Y}_{t-1}}(y_t|\mathcal{Y}_{t-1})$$

The log-likelihood function was defined manually in R. First, the covariance matrix and the system state calculations were defined as below.

**Predictive covariance matrix**
$$\hat{\Sigma}_{t|t-1}=\hat{\Sigma}_{t-1|t-1}+M$$

**Posterior covariance matrix**
$$\hat{\Sigma}_{t|t}=\hat{\Sigma}_{t|t-1}-\hat{\Sigma}_{t|t-1}C'_t(C_t\hat{\Sigma}_{t|t-1}C'_t+N_t)^{-1}C_t\hat{\Sigma}_{t|t-1}$$

**System state prediction**
$$\hat{x}_{t|t-1}=\hat{x}_{t-1|t-1}$$

**System state update**
$$\hat{x}_{t|t}=\hat{x}_{t-1|t-1}+\hat{\Sigma}_{t|t}C'_tN_t^{-1}(y_t-C_t\hat{x}_{t-1|t-1}-D_tu)$$

```{r updatefunctions}
### Predictive covariance matrix ###
sigma_pred <- function(t, seasoni, sig0, sigW, sigV){
  sigma_post(t - 1, seasoni, sig0, sigV, sigW)
}

### Posterior covariance mtrix ###
sigma_post <- function(t, seasoni, sig0, sigV, sigW){
  if(t > 0){
    Ct <- getC(t, seasoni) # C_t
    mt <- nrow(Ct)  # m: number of games on day t
    Nt <- sigW*diag(mt) # N: 
    sprev <- sigma_pred(t, seasoni, sig0, sigV, sigW)
    return(sprev - 
             sprev%*%t(Ct)%*%
             solve(Ct%*%sprev%*%t(Ct) + Nt)%*%
             Ct%*%sprev)
  }
  else{
    (sig0 + sigV)*diag(30)
  }
}

### System state prediction ###
x_pred <- function(t, seasoni, x0, sig0, sigV, sigW, u, clevel = 0){
  x_post(t - 1, seasoni, x0, sig0, sigV, sigW, u, clevel)
}

### System state update ###
x_post <- function(t, seasoni, x0, sig0, sigV, sigW, u, clevel = 0){
  if(t > 0){
    Ct <- getC(t, seasoni) # C_t
    Dt <- getD(t, seasoni, clevel) # D_t
    yt <- getY(t, seasoni) # y_t, point differentials on games in t-th game day
    mt <- nrow(Ct)  # m: number of games on day t
    Nt <- sigW*diag(mt) # N:
    xprev <- x_post(t - 1, seasoni, x0, sig0, sigV, sigW, u, clevel) # X-hat_t-1 | t-1
    spost <- sigma_post(t, seasoni, sig0, sigV, sigW) # Sigma-hat_t | t
    if(clevel == 0)
      return(xprev + (1/sigW)*spost%*%t(Ct)%*%(yt - Ct%*%xprev - u*Dt))
    return(xprev + (1/sigW)*spost%*%t(Ct)%*%(yt - Ct%*%xprev - Dt%*%u))
  }
  else{
    x0
  }
}
```

Then, the negative of log-likelihood function was defined as below.

```{r nloglikelihood}
### negative log-likelihood for a single game ###
loglike <- function(pars, t, seasoni, x0, u = NULL){
  sig0 <- pars[1]
  sigV <- pars[2]
  sigW <- pars[3]
  if(!is.na(pars[4])) u = pars[4]
  
  Ct <- getC(t, seasoni)
  Dt <- getD(t, seasoni, 0)
  Yt <- getY(t, seasoni)
  xpred <- x_pred(t, seasoni, x0, sig0, sigV, sigW, u)
  spred <- sigma_pred(t, seasoni, sig0, sigV, sigW)
  Nt <- sigW*diag(nrow(Ct))
  
  yhat <- Ct%*%xpred + u*Dt
  Ohat <- Ct%*%spred%*%t(Ct) + Nt
  
  ydiff <- Yt - yhat
  
  # gives negative likelihood
  loglik <- log(det(Ohat)) + t(ydiff)%*%solve(Ohat)%*%ydiff 
  return(as.numeric(loglik))
}

### total negative log-likelihood for multiple games ###
nLoglike <- function(pars, seasoni, x0s, us = NULL, numdts = 20){
  x0 <- x0s[,seasoni]
  u <- us[seasoni]
  gamedays <- c(1: numdts)
  sum(sapply(gamedays, FUN = loglike, pars = pars, 
              seasoni = seasoni, x0 = x0, u = u))
}
```

In order to minimize the negative log-likelihood function, `optim` function was used. The parameters were initialized with the following code.

```{r initpar}
set.seed(20160806)
pars <- c(100,100,100, rnorm(1, 2))
```

The initial system states for each season, $x_{t|t}$, were initialized based on the previous year's final ranking. The final rankings for seasons from 2010 to 2015 were retrieved from <http://www.baseball-reference.com/>. The downloaded files can be found at <https://github.com/mjmoon/timeseriesFin/tree/master/data>. The state values were initalized such that the values summed to zero by subtracting the mean ranking.

$$x_{0|0; \text{rank i}}:=15.5-i$$

```{r initx}
library(RCurl)
franks <- list()
gitURL <- getURL("https://rawgit.com/mjmoon/timeseriesFin/master/data/rank2010.csv")
franks[[1]] <- read.csv(text = gitURL)
gitURL <- getURL("https://rawgit.com/mjmoon/timeseriesFin/master/data/rank2011.csv")
franks[[2]] <- read.csv(text = gitURL)
gitURL <- getURL("https://rawgit.com/mjmoon/timeseriesFin/master/data/rank2012.csv")
franks[[3]] <- read.csv(text = gitURL)
gitURL <- getURL("https://rawgit.com/mjmoon/timeseriesFin/master/data/rank2013.csv")
franks[[4]] <- read.csv(text = gitURL)
gitURL <- getURL("https://rawgit.com/mjmoon/timeseriesFin/master/data/rank2014.csv")
franks[[5]] <- read.csv(text = gitURL)

getx0 <- function(rankscsv){
  rankscsv <- rankscsv[-31,1:2]
  rankscsv$x0 <- 14.5:-14.5
  rankscsv$Tm <- as.character(rankscsv$Tm)
  # rankscsv$Tm[!rankscsv$Tm %in% teamIds]
  rankscsv$Tm[rankscsv$Tm == "NYY"] <- "NYA"
  rankscsv$Tm[rankscsv$Tm == "LAA"] <- "ANA"
  rankscsv$Tm[rankscsv$Tm == "LAD"] <- "LAN"
  rankscsv$Tm[rankscsv$Tm == "STL"] <- "SLN"
  rankscsv$Tm[rankscsv$Tm == "SFG"] <- "SFN"
  rankscsv$Tm[rankscsv$Tm == "FLA"] <- "MIA"
  rankscsv$Tm[rankscsv$Tm == "TBR"] <- "TBA"
  rankscsv$Tm[rankscsv$Tm == "CHC"] <- "CHN"
  rankscsv$Tm[rankscsv$Tm == "CHW"] <- "CHA"
  rankscsv$Tm[rankscsv$Tm == "SDP"] <- "SDN"
  rankscsv$Tm[rankscsv$Tm == "NYM"] <- "NYN"
  rankscsv$Tm[rankscsv$Tm == "KCR"] <- "KCA"
  rankscsv$Tm[rankscsv$Tm == "WSN"] <- "WAS"
  rankscsv$Tm <- factor(rankscsv$Tm, teamIds)
  # rankscsv$Tm[!rankscsv$Tm %in% teamIds]
  rankscsv <- rankscsv[order(rankscsv$Tm), ]
  return(rankscsv$x0)
}

x0s <- sapply(franks, getx0)
```

The optimizations were performed for each season as shown below.

```{r optimize, eval = FALSE}
## intercept
parest1 <- optim(pars, nLoglike, seasoni = 1, x0s = x0s, 
                 method = "L-BFGS-B", 
                 lower = c(5,5,5,-0.1), upper = c(1000,1000,1000,1.5))
parest2 <- optim(pars, nLoglike, seasoni = 2, x0s = x0s, 
                 method = "L-BFGS-B", 
                 lower = c(5,5,5,-0.1), upper = c(1000,1000,1000,1.5))
parest4 <- optim(pars, nLoglike, seasoni = 4, x0s = x0s, 
                 method = "L-BFGS-B", 
                 lower = c(5,5,5,-0.1), upper = c(1000,1000,1000,1.5))
parest5 <- optim(pars, nLoglike, seasoni = 5, x0s = x0s, 
                 method = "L-BFGS-B", 
                 lower = c(5,5,5,-0.1), upper = c(1000,1000,1000,1.5))
parest6 <- optim(pars, nLoglike, seasoni = 6, x0s = x0s, 
                 method = "L-BFGS-B", 
                 lower = c(5,5,5,-0.1), upper = c(1000,1000,1000,1.5))
utoptim <- rbind(parest1$par, parest2$par, parest3$par, parest4$par, parest5$par)
colnames(utoptim) <- c("sig0", "sigV", "sigW", "u_intercept")
rownames(utoptim) <- c("S2011", "S2012", "S2013", "S2014", "S2015")
print(round(utoptim,2))
```

```{r optimizeTmp, echo = FALSE}
utoptim <- matrix(rep(c(200, 0.005, 2.5, 2.5), 5), nrow = 5, ncol = 4, byrow = TRUE)
colnames(utoptim) <- c("sig0", "sigV", "sigW", "u_intercept")
rownames(utoptim) <- c("S2011", "S2012", "S2013", "S2014", "S2015")
print(round(utoptim,2))
```

For the second model, the maximum likelihood estimation was not conducted in order to save the computational time. Instead, the same estimates were used for the system variances while the coefficients for the covariates were estimated using linear regression on the first 20 games. 

$$y=Du+\epsilon \text{ where } \epsilon \sim N(0,\sigma^2)$$

```{r lmu}
utlm <- t(sapply(dataSeasons, function(x) 
  coef(lm(ScoreDiff ~ DblHdr + Host, data = subset(x, HmVis == 1)))))
rownames(utlm) <- c("S2011", "S2012", "S2013", "S2014", "S2015")
print(round(utlm,2))
```

#### The Kalman filter ####

The Kalman filter was fitted using the `FKF` <https://cran.r-project.org/web/packages/FKF/FKF.pdf> package. 

```{r kmfilter, message = FALSE}
library(FKF)
mlbkm <- function(seasoni, covs = F){
  if(covs) {
    u <- array(c(utoptim[seasoni,-c(1:3)], utlm[seasoni,]), c(32,1))
    level <- 2
  } else {
    u <- array(utoptim[seasoni, 4], c(1, 1))
    level <- 0
  }
  gamedays <- which(!unique(scoreSeasons[[seasoni]]$Tind) %in% c(1:20))
  yt <- sapply(gamedays, getY18, seasoni)
  Ct <- sapply(gamedays, getC18, seasoni, simplify = "array")
  Dt <- sapply(gamedays, getD18, seasoni, level, simplify = "array")
  if(!covs) Dt <- array(Dt, dim = c(18, 1, ncol(Dt)))
  uDt <- apply(Dt, 3, function(x) x%*%u)
  
  testkf <- fkf(a0 = x0s[,seasoni], 
                P0 = utoptim[seasoni, 1]*diag(30),
                dt = matrix(0, nrow = 30, ncol = 1),
                ct = uDt, 
                Tt = array(diag(30), c(30,30,1)),
                Zt = Ct,
                HHt = array(utoptim[seasoni, 2]*diag(30), c(30,30,1)), 
                GGt = array(utoptim[seasoni, 3]*diag(18), c(18,18,1)),
                yt)
  
  xtts <- testkf$att
  xts <- testkf$at
  yts <- yt - round(testkf$vt)
  ytvec <- as.vector(yt)
  winprederr <- sum((as.vector(yts > 0)[ytvec != 0]) != 
                       (ytvec[ytvec != 0] > 0))/sum(ytvec != 0)
  scoremse <- sum((as.vector(testkf$vt)[ytvec != 0])^2)/sum(ytvec != 0)
  return(list(xpost = xtts, xpred = xts, ypred = yts,
              gprederr = winprederr, smse = scoremse))
}
### Fit intercept-only model ###
kmfres.int <- lapply(c(1:5), mlbkm)
### Fit covariate model ###
kmfres.cov <- lapply(c(1:5), mlbkm, covs = T)
```

```{r validdt, include = FALSE}
getSmse <- function(res) {
  return(res$smse)
}
getGpred <- function(res) {
  return(res$gprederr)
}

smse.int <- data.frame(value = sapply(kmfres.int, getSmse))
smse.cov <- data.frame(value = sapply(kmfres.cov, getSmse))

perr.int <- data.frame(value = sapply(kmfres.int, getGpred))
perr.cov <- data.frame(value = sapply(kmfres.cov, getGpred))

smse.int$model <- "Intercept-only"
smse.cov$model <- "With covariates"

perr.int$model <- "Intercept-only"
perr.cov$model <- "With covariates"

smse.int$var <- "smse"
smse.cov$var <- "smse"

perr.int$var <- "perr"
perr.cov$var <- "perr"

smse.int$season <- c(2011:2015)
smse.cov$season <- c(2011:2015)

perr.int$season <- c(2011:2015)
perr.cov$season <- c(2011:2015)

validdt <- rbind(smse.int, smse.cov, perr.int, perr.cov)
```

###Results###

```{r plotxt, echo = FALSE}
library(ggplot2)
xdt <- as.data.frame(rbind(x0s[,5], t(kmfres.int[[5]]$xpost)))
names(xdt) <- teamIds
xdt.m <- melt(as.matrix(xdt))
names(xdt.m) <- c("Day", "Team", "Rating")
xdt.m$Day <- xdt.m$Day + 19
ggplot(data = subset(xdt.m, Team == "TOR" | Team == "BAL" |
                       Team == "BOS" | Team == "NYA" | 
                       Team == "TBA")) + theme_minimal() +
  geom_line(aes(x = Day, y = Rating, col = Team)) +
  labs(title = "2015 AL Easton Division rating estimation") 
```

The plot above shows the estimated relative team strengths of the 5 teams in AL Easton Division during the 2015 season. The graph shows little difference between teams.

```{r plotvalid, echo = FALSE}
ggplot(data = subset(validdt, var == "smse")) + theme_minimal() +
  geom_bar(aes(x = season, y = value, fill = model), stat = "identity", 
           position = "dodge") +
  labs(x = "Season", y = "MSEs", title = "Score MSEs") +
  scale_fill_discrete(name = "Models") 

ggplot(data = subset(validdt, var == "perr")) + theme_minimal() +
  geom_bar(aes(x = season, y = value, fill = model), stat = "identity", 
           position = "dodge") +
  labs(x = "Season", y = "Error rates", title = "Game prediction error rates") +
  scale_fill_discrete(name = "Models") +
  coord_cartesian(ylim = c(0,1))
```

The two plots above show mean squared errors of score predictions and prediction error rates of game winners for each season from the two models. Both models could only predict the game winners about 50% of the time. Adding the doubleheader and hosting team covariates did not help improve the prediciton error rate nor the mean squared errors. 

### Discussion ###

#### Conclusion ####

The state-space models and the Kalman filter used in this study resulted in a prediction error rate of ~50%. The poor performance contrasts the performace of the NBA model presented in the original paper. Its model was able to predict ~65% to ~70% of the game winners.

Also, there was no improvement in performance when doubleheader and hosting team covariates were added. The covariates were added to test if doubleheaders and different teams had different amount of home advantages. The model was not able to detect any differences in the final score differences caused by these covariates.

#### Further improvements ####

+ **Parameter calibration**: In this study, only the first 20 games of each season were used to calibrate the parameters. In the original study, an entire season - the current or the previous - was used. Increasing the number of the current season games used to estimate the parameters or using the previous season may improve the performance of the model.
+ **Covariate selection**: The covariate model in this study only used static information. However, dynamic covariates may be used to estimate the score differences. These may include information on players on streak, starting pitcher's ERA, team's recent batting average, etc. 

#### Utilization ####

+ ...

### References ###

